{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPscdma3ERyQp7i5uACVZFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hereagain-Y/TCR_VAE/blob/main/Brian_lungtrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latent space frist then pairs"
      ],
      "metadata": {
        "id": "fU5EttsdB2w4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test latent distance calculation on GPU"
      ],
      "metadata": {
        "id": "GuEuq4gXwpY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd \n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pkgutil import extend_path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from six.moves import xrange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "#\n",
        "from scipy.spatial import distance\n",
        "import random \n",
        "from scipy import spatial\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "ghL3m2j2hVYV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81eNsV8Ehgmj",
        "outputId": "dea2e56d-3625-47e0-f881-f5640455af8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dsQCRFrOr8MG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SllPr2UjsrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AAs= ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "index_code = {}\n",
        "code_index = {}\n",
        "l_max = 20\n",
        "for i in range(len(AAs)):\n",
        "    index_code[i] = AAs[i]\n",
        "    code_index[ AAs[i] ] = i\n",
        "\n",
        "def oneHotEncode(seq, l_max=l_max, index_code=index_code, code_index=code_index):\n",
        "    n_amino = 20\n",
        "    matrix = np.zeros((l_max,n_amino)).astype(int)\n",
        "    for i in range(len(seq)):\n",
        "        matrix[ i , code_index[seq[i]] ] = 1\n",
        "    return matrix\n",
        "\n",
        "# pca encoded \n",
        "pca_index = pd.read_csv(\"/content/drive/My Drive/DL/VAE/AA_indexPCA.csv\")\n",
        "d=pca_index.set_index('Unnamed: 0').T.to_dict('list')\n",
        "\n",
        "\n",
        "# pca normalization\n",
        "data = d.items()\n",
        "list_dat = list(d.values())\n",
        "arr = np.array(list_dat)\n",
        "ex = np.array(arr)\n",
        "ex_norm = (ex-ex.min(axis=0))/(ex.max(axis=0)-ex.min(axis=0))\n",
        "\n",
        "AAs=np.array(list(d.keys()))\n",
        "new_pca = {}\n",
        "\n",
        "for i in np.arange(20):\n",
        "    new_pca[AAs[i]]=ex_norm[i]\n",
        "\n",
        "new_pca\n",
        "d= new_pca\n",
        "\n",
        "def AAindexEncoding(Seq):\n",
        "    length_seq=len(Seq)\n",
        "    global l_max\n",
        "    AAE=np.zeros([l_max,20])\n",
        "    if length_seq<l_max:\n",
        "        for amino in range(length_seq):\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA] # add PC value \n",
        "            \n",
        "        for amino in range(length_seq,l_max):\n",
        "            AAE[amino,]=np.zeros(20)\n",
        "    else: \n",
        "        for amino in range(length_seq): # zero padding\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA]\n",
        "        \n",
        "    #AAE=np.transpose(AAE.astype(np.float32)) # row as PC. and column as AA sequence \n",
        "    return AAE \n",
        "\n",
        "  \n",
        "def GetFeatures(file):\n",
        "    hot_encode=[]\n",
        "    for seq in file:\n",
        "        hot_encode.append(AAindexEncoding(seq))\n",
        "    hot_encode=np.array(hot_encode,dtype=np.float32)\n",
        "    result=np.array(hot_encode,dtype=np.float32)\n",
        "    return(result)"
      ],
      "metadata": {
        "id": "GAEdkNvmhpaA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=datetime.now()"
      ],
      "metadata": {
        "id": "M_acp4p4i2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True\n",
        "channels =1\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
      ],
      "metadata": {
        "id": "FV6qxP4HjDZ2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self,h_dim=64*10*10, z_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1), #16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1), # 12\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1), #10\n",
        "            nn.ReLU()\n",
        "        \n",
        "        )\n",
        "\n",
        "        \n",
        "        \n",
        "        # mean 64*5*5 =\n",
        "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
        "        # var \n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        # for decoder layer \n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            \n",
        "   \n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def reparameterize(self, mu):\n",
        "        #std = logvar.mul(0.5).exp_()\n",
        "        # return torch.normal(mu, std)\n",
        "        #esp = torch.randn(*mu.size())\n",
        "        z = mu\n",
        "        return z\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu= self.fc1(h)\n",
        "        z = self.reparameterize(mu)\n",
        "        return mu, z\n",
        "        \n",
        "    def representation(self, x):\n",
        "        return self.bottleneck(self.encoder(x))[0] # latent layer \n",
        "\n",
        "        \n",
        "    \n",
        "    #def alignmentscore(self,x,y):\n",
        "    #    scores = pairwise2.align.localds(x,y,align_matrix,open=open_penalty,extend=gap_penalty)\n",
        "    #    score_align = scores[0].score\n",
        "    #    return score_align\n",
        "        \n",
        "    def latent(self,x,y):\n",
        "        l1 = self.encoder(x)# 32\n",
        "        l1 = l1.view(-1,64*10*10) # 32\n",
        "        l1, mu1 = self.bottleneck(l1)\n",
        "\n",
        "        l2 = self.encoder(y)# 32\n",
        "        l2 = l2.view(-1,64*10*10) # 32\n",
        "        l2, mu2 = self.bottleneck(l2)\n",
        "        # use cos-simialrity\n",
        "        #latent_dist =np.sqrt( np.sum(np.square(l1 - l2)) )\n",
        "        \n",
        "        \n",
        "        return l1,l2\n",
        "\n",
        "    def forward(self, x,y):\n",
        "      # for dataset 1\n",
        "        h1= self.encoder(x)\n",
        "        h1 = h1.view(-1,64*10*10)\n",
        "        z1, mu1 = self.bottleneck(h1) #\n",
        "        z1 = self.fc3(z1) # 64*10*10\n",
        "        z1 = z1.view(-1,64,10,10)\n",
        "        z1 = self.decoder(z1)\n",
        "      # for dat2   \n",
        "        h2= self.encoder(y)\n",
        "        h2 = h2.view(-1,64*10*10)\n",
        "        z2, mu2 = self.bottleneck(h2)\n",
        "        z2 = self.fc3(z2)\n",
        "        z2 = z2.view(-1,64,10,10)\n",
        "        z2 = self.decoder(z2)\n",
        "        \n",
        "        # aligment \n",
        "        #s = self.alignmentscore(x,y)\n",
        "        # latent distance\n",
        "        l1,l2 = self.latent(x,y)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return z1, mu1,z2,mu2,l1,l2"
      ],
      "metadata": {
        "id": "u3y3cf7ajE5l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torch.load('/content/drive/MyDrive/DL/CNNVAE/Paired_sigmoid_modified_1000_echo_cat_train.apx')"
      ],
      "metadata": {
        "id": "SQhWk3kKjK1b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move model to gpu\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "-xZnHK8bv5QX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Brain&Lung Data"
      ],
      "metadata": {
        "id": "zMFyAIboKAwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_test = pd.read_csv('/content/drive/My Drive/DL/Lung_data/1_Brain_Met.txt',delimiter='\\t',header=None,names=['seq','count'])\n",
        "seq_test['length'] = [len(seq) for seq in seq_test['seq']]\n",
        "\n",
        "seq_test = seq_test[ seq_test['length']<=20 ]\n"
      ],
      "metadata": {
        "id": "8A14OWaCKhlk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "KhvDfWobLmJx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read data into csv \n",
        "data_files = r\"/content/drive/My Drive/DL/Lung_data/\"\n",
        "df_mango= pd.DataFrame()\n",
        "all_files = glob.glob(os.path.join(data_files , \"*Brain_Met.txt\"))\n",
        "brain =[]\n",
        "counts=[]\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename,delimiter='\\t',header=None,names=['seq','count'])\n",
        "    df=df.iloc[1:,:]\n",
        "    df['length'] = [len(seq) for seq in df['seq']]\n",
        "    df= df[ df['length']<=20 ]\n",
        "    count=len(df['seq'])\n",
        "    brain.append(df)\n",
        "    counts.append(count)\n",
        "brain_data= pd.concat(brain, axis=0, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "aay7rWCdL80z"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lung_file =glob.glob(os.path.join(data_files , \"*Lung.txt\"))\n",
        "lung=[]\n",
        "counts2=[]\n",
        "for filename in lung_file:\n",
        "    df = pd.read_csv(filename,delimiter='\\t',header=None,names=['seq','count'])\n",
        "    df=df.iloc[1:,:]\n",
        "    df['length'] = [len(seq) for seq in df['seq']]\n",
        "    df= df[ df['length']<=20 ]\n",
        "    count=len(df['seq'])\n",
        "    lung.append(df)\n",
        "    counts2.append(count)\n",
        "lung_data= pd.concat(lung, axis=0, ignore_index=True)\n",
        "#lung_data=pd.concat((pd.read_csv(f,delimiter='\\t',header=None,names=['seq']) for f in lung_file ),axis=0,ignore_index=False)"
      ],
      "metadata": {
        "id": "g9parRjzNyuO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brain_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g8ruqFkuOY-X",
        "outputId": "366161e7-7e60-43ff-c726-73a6a25553b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               seq count  length\n",
              "0   CAAGAGLSTDTQYF     1      14\n",
              "1      CAGERAYEQYF     1      11\n",
              "2  CAGKPSGSGANVLTF     1      15\n",
              "3    CAIGTGGLSEAFF     1      13\n",
              "4    CAILAGGQETQYF     1      13"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c92e118-3aa3-4839-9ab0-256e89868749\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq</th>\n",
              "      <th>count</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CAAGAGLSTDTQYF</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CAGERAYEQYF</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CAGKPSGSGANVLTF</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CAIGTGGLSEAFF</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CAILAGGQETQYF</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c92e118-3aa3-4839-9ab0-256e89868749')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c92e118-3aa3-4839-9ab0-256e89868749 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c92e118-3aa3-4839-9ab0-256e89868749');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_count(data,count):\n",
        "  if (len(data)%2==0):\n",
        "    count=count\n",
        "    print(len(data))\n",
        "  else:\n",
        "    print('this is odd')\n",
        "    count[(len(lung_file)-1)]=  count[(len(lung_file)-1)]-1\n",
        "  return count"
      ],
      "metadata": {
        "id": "5-dKfVIlPCbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts=check_count(brain_data,counts)\n",
        "counts2=check_count(lung_data,counts2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfz52-8gPDCs",
        "outputId": "797ee79d-e8b8-4928-c88e-39b84fd91db0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is odd\n",
            "this is odd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_data(data):\n",
        "  if (len(data)%2==0):\n",
        "    data= data\n",
        "    print(len(data))\n",
        "  else:\n",
        "    print('this is odd')\n",
        "    data=data[:-1]\n",
        "  return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pGGRlJ8V0bK0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YeNCORp34Yr",
        "outputId": "491ed2f5-98f8-4390-b763-bc51e798827c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[865, 1703, 520, 6260, 1256, 469, 804, 1877, 961]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzKG2sO35-G",
        "outputId": "1a04497a-4c19-4093-c7a8-ad2adf3ab415"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4124, 5432, 6069, 1011, 6375, 8090, 2041, 1269, 4446]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex=counts+counts2"
      ],
      "metadata": {
        "id": "Juy1z1tv38AR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZbp5HLj3mnm",
        "outputId": "a65b33cc-5b93-4b1a-e6b4-6c089761a490"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is odd\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[865, 1703, 520, 6260, 1256, 469, 804, 1877]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lung_data=check_data(lung_data)\n",
        "brain_data = check_data(brain_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqRqpXfp13IN",
        "outputId": "e13ec2b2-f7e8-4908-baf0-18666a772480"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is odd\n",
            "this is odd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lung_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLEk5SMkQrq8",
        "outputId": "f26a25ed-5c04-4f3e-9244-8e38a709111d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38856"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_brain=list(brain_data['seq'])"
      ],
      "metadata": {
        "id": "7fDUctLlQTG-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lung=list(lung_data['seq'])"
      ],
      "metadata": {
        "id": "AWr1ZuNSRkFf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AA_b1=GetFeatures(seq_brain[:int(len(brain_data)/2)]) # 5000\n",
        "AA_b2=GetFeatures(seq_brain[int(len(brain_data)/2):len(brain_data)]) #5000\n",
        "\n",
        "AA_l1=GetFeatures(seq_lung[:int(len(lung_data)/2)]) # 5000\n",
        "AA_l2=GetFeatures(seq_lung[int(len(lung_data)/2):len(lung_data)]) #5000\n",
        "\n",
        "train_loaderx= DataLoader(torch.from_numpy(AA_b1).float(), batch_size=1000, shuffle=False)\n",
        "train_loadery = DataLoader(torch.from_numpy(AA_b2).float(),batch_size=1000,shuffle=False)\n",
        "\n",
        "lung_loaderx= DataLoader(torch.from_numpy(AA_l1).float(), batch_size=1000, shuffle=False)\n",
        "lung_loadery = DataLoader(torch.from_numpy(AA_l2).float(),batch_size=1000,shuffle=False)"
      ],
      "metadata": {
        "id": "m_QlO81oCPfh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent1=[]\n",
        "latent2=[]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (x, y) in enumerate(zip(train_loaderx, train_loadery)):\n",
        "        x=x.view(len(x),1,20,20).to(device)\n",
        "        y=y.view(len(y),1,20,20).to(device)\n",
        "        x_hat, mean_x,y_hat,mean_y,l1,l2= model(x,y)\n",
        "        #dis = torch.nn.functional.pairwise_distance(l1, l2,2)\n",
        "        latent1.append(l1)\n",
        "        latent2.append(l2)"
      ],
      "metadata": {
        "id": "KcTE9t21CbJn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_l1 = torch.cat(latent1)\n",
        "stacked_l2 = torch.cat(latent2)\n"
      ],
      "metadata": {
        "id": "QXOfKcItkULk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stack_l1 =stacked_l1.cpu().detach().numpy()\n",
        "stack_l2=stacked_l2.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "FgP4VT8tDem6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_brain=np.concatenate((stack_l1,stack_l2), axis=0)\n"
      ],
      "metadata": {
        "id": "fzjQxgPNJ8pM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_brain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XmBnlTq3AlU",
        "outputId": "4e6906e1-70f9-4b42-822f-95d6ce242a9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14714, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent3=[]\n",
        "latent4=[]\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (x, y) in enumerate(zip(lung_loaderx, lung_loadery)):\n",
        "        x=x.view(len(x),1,20,20).to(device)\n",
        "        y=y.view(len(y),1,20,20).to(device)\n",
        "        x_hat, mean_x,y_hat,mean_y,l1,l2= model(x,y)\n",
        "        #dis = torch.nn.functional.pairwise_distance(l1, l2,2)\n",
        "        latent3.append(l1)\n",
        "        latent4.append(l2)\n",
        "stacked_l3 = torch.cat(latent3)\n",
        "stacked_l4 = torch.cat(latent4)\n",
        "stack_l3 =stacked_l3.cpu().detach().numpy()\n",
        "stack_l4=stacked_l4.cpu().detach().numpy()\n",
        "latent_lung=np.concatenate((stack_l3,stack_l4), axis=0)"
      ],
      "metadata": {
        "id": "ghh0yBR_U4Hs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_seq= np.concatenate((latent_brain,latent_lung),axis=0)"
      ],
      "metadata": {
        "id": "BwLtb9poZpOe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = torch.from_numpy( np.array(total_seq)).float()"
      ],
      "metadata": {
        "id": "kdkarIoh3KKo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences.shape # check dim is ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRFxlqYT3N6R",
        "outputId": "8de321d4-77e4-4c0f-9654-ff25837b7e7c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([53570, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqo708xe23Xr",
        "outputId": "2de5f305-de15-4e4f-b202-541599cb36cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 21.8486, -13.9713,  -4.2095,  18.5930,  -5.4254,  -1.2194,  19.9250,\n",
              "          8.1279, -31.9806,  17.0616,  12.3843,  14.4362,  -5.9183, -10.7043,\n",
              "         -8.4698,   9.8114,  -5.7981,  16.0426,  -4.5814,   1.3349,  -1.2115,\n",
              "         -6.7483,   8.3194,  22.3002, -17.1692,  -4.8241,  14.4490, -12.6214,\n",
              "          3.7298,  20.6780,  24.0889,   8.8792])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine data together \n",
        "# 9 lung 9 brain "
      ],
      "metadata": {
        "id": "KPlw3IfzVtub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSampleIndex(sample):\n",
        "    sample_list = list( set(sample) )\n",
        "    sample_array = np.array(sample)\n",
        "    sample_index = []\n",
        "    for s in sample_list:\n",
        "        sample_index.append( np.where(sample_array==s)[0] )\n",
        "    return sample_list, sample_index\n",
        "\n",
        "def gen_multi_list(amount, length):\n",
        "    seqs = np.random.default_rng()\n",
        "    return [seqs.random(length) for _ in range(amount)]\n",
        "\n",
        "sequences = gen_multi_list(1000,16) #50*10\n",
        "sequences = torch.from_numpy( np.array(sequences)).float()\n",
        "counts =[]\n",
        "for i in range(0,1000):\n",
        "    n=random.randint(1, 5)\n",
        "    counts.append(n)\n",
        "\n",
        "counts = torch.from_numpy( np.array( counts ) ).float()\n",
        "A = ['a','b','c','d','e','f','g','h','i','j']\n",
        "\n",
        "\n",
        "samples=list(itertools.chain.from_iterable(itertools.repeat(x, 10) for x in A))\n",
        "label =[]\n",
        "for i in range(0,10):\n",
        "    n=random.randint(0, 1)\n",
        "    label.append(n)\n",
        "labels = np.repeat(label,10)\n",
        "  \n",
        "\n",
        "sample_label_map = { i:j for (i,j) in zip(samples,labels) }\n",
        "label=torch.from_numpy(np.array( label ).reshape( (len(label),1) )).float()"
      ],
      "metadata": {
        "id": "mYbcIcLDVxcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSampleIndex(sample):\n",
        "    sample_list = list( set(sample) )\n",
        "    sample_array = np.array(sample)\n",
        "    sample_index = []\n",
        "    for s in sample_list:\n",
        "        sample_index.append( np.where(sample_array==s)[0] )\n",
        "    return sample_list, sample_index"
      ],
      "metadata": {
        "id": "-7dM6qODWFen"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count1 = list(brain_data['count'].astype(float))\n",
        "count2 = list(lung_data['count'].astype(float))"
      ],
      "metadata": {
        "id": "Yk-RM4ZSX-XJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFADyzqdPjDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_total = count1+count2"
      ],
      "metadata": {
        "id": "JXVwdXFP5plK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_total = torch.from_numpy( np.array( count_total ) ).float()"
      ],
      "metadata": {
        "id": "oYK6uXuk3ZbI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(count_total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpeE0ECdoxm",
        "outputId": "8cb4b2b6-32a3-438e-b68d-a7ff230b72d3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_total.shape\n",
        "count_total[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70o-NxM03dUY",
        "outputId": "fb735626-e9fe-4ec2-dfdf-49ede36c3a1a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r']"
      ],
      "metadata": {
        "id": "FyFtcuUpZI18"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain, repeat"
      ],
      "metadata": {
        "id": "1PIvJZK0Y_e9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_counts = counts+counts2"
      ],
      "metadata": {
        "id": "J0NrbYKB6Z3j"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ur1Ovf8VNzoO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_data(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUNWjRI8NUPv",
        "outputId": "16fa4217-2462-4ee3-d558-6336558f74e6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is odd\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[865, 1703, 520, 6260, 1256, 469, 804, 1877]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_data(counts2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk_o-YsdNgD_",
        "outputId": "5bf03bb6-4527-418a-be4f-21c10a5f24c7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is odd\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4124, 5432, 6069, 1011, 6375, 8090, 2041, 1269]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line_counts[8]=counts[8]-1\n",
        "line_counts[17]=counts2[8]-1"
      ],
      "metadata": {
        "id": "ToXm1xiA4UQ2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn8_UnDrNjK5",
        "outputId": "80259b10-704a-4787-8711-957087769c0a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[865,\n",
              " 1703,\n",
              " 520,\n",
              " 6260,\n",
              " 1256,\n",
              " 469,\n",
              " 804,\n",
              " 1877,\n",
              " 960,\n",
              " 4124,\n",
              " 5432,\n",
              " 6069,\n",
              " 1011,\n",
              " 6375,\n",
              " 8090,\n",
              " 2041,\n",
              " 1269,\n",
              " 4445]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples=list(chain.from_iterable((repeat(item, cnt) for item, cnt in zip(A,line_counts))))"
      ],
      "metadata": {
        "id": "yQjYbxvdWHhf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UawlVONf3f1U",
        "outputId": "d59b01cd-0826-40e3-d61a-3b647f84dba1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53570"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label=[0,1]\n",
        "labels=list(itertools.chain.from_iterable(itertools.repeat(x, 9) for x in label))\n",
        "labels=torch.from_numpy(np.array( labels ).reshape( (len(labels),1) )).float()"
      ],
      "metadata": {
        "id": "q7tyFDLEaQCM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfwfeYX44dg9",
        "outputId": "b24fc6c6-b0b2-4e71-c661-827987ac415a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#seq_counts=np.concatenate((brain_data['count'].astype(float),lung_data['count'].astype(float)),axis=0)"
      ],
      "metadata": {
        "id": "svdLDI-maviu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.L = 32 # 512 node fully connected layer\n",
        "        self.D =  8# 128 node attention layer\n",
        "        self.K = 1\n",
        "\n",
        "        # get attention score  make it into 1 dim \n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.L, self.K),\n",
        "            nn.Tanh() # nn,SELU()\n",
        "           \n",
        "            \n",
        "        )\n",
        "        \n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.L * self.K, 1), # 16,1 \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self,sequence,sample,count):\n",
        "        A = self.attention(sequence)\n",
        "        count_col = count.reshape(-1,1)\n",
        "        A = A*count_col\n",
        "        newA= torch.clone(A)\n",
        "        sample_list, sample_index = getSampleIndex(sample)\n",
        "        sample_feature = []\n",
        "        for i in range(len(sample_list)):\n",
        "            seq_numbers = sample_index[i]\n",
        "            seqs_in_bag = sequence[seq_numbers]\n",
        "            attention_bag = A[seq_numbers]\n",
        "            attention_bag = torch.softmax(attention_bag,dim=0)\n",
        "            seq_feature = seqs_in_bag*attention_bag\n",
        "            sample_feature.append(seq_feature.sum(dim=0))\n",
        "            newA[seq_numbers] = attention_bag\n",
        "        sample_feature =torch.stack(sample_feature,dim=0)\n",
        "        \n",
        "        predictions = self.classifier(sample_feature) \n",
        "        Y_hat = torch.ge(predictions, 0.5).float() \n",
        "        return predictions,Y_hat, sample_list, newA"
      ],
      "metadata": {
        "id": "v7R4IHyTeXfO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function( label, prediction ):\n",
        "    reproduction_loss = nn.functional.binary_cross_entropy(label, prediction, reduction='sum')\n",
        "    return reproduction_loss\n",
        "       \n",
        "def calculate_classification_error(Y_hat,Y):\n",
        "    Y = Y.float()\n",
        "    error = 1. - Y_hat.eq(Y).cpu().float().mean().data\n",
        "\n",
        "    return error, Y_hat  "
      ],
      "metadata": {
        "id": "7i0WmeRUebqZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.optim import Adam\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)  \n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "1tB1QseHgdA1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8g6i62SNhlxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Attmodel = Attention()"
      ],
      "metadata": {
        "id": "OZcxZpxdmTBd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list, sample_index=getSampleIndex(samples)"
      ],
      "metadata": {
        "id": "P7ZklT9LdzUY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_numbers=sample_index[5]\n",
        "seqs_in_bag = sequences[seq_numbers]\n"
      ],
      "metadata": {
        "id": "ceTrh_59d6cB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000\n",
        "def plotCurve(x_vals,y_vals,x_label, y_label,\n",
        "              x2_vals=None, y2_vals=None, legend=None,figsize=(3.5,2.5)):\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.semilogy(x_vals, y_vals)\n",
        "    if x2_vals and y2_vals:\n",
        "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
        "    \n",
        "    if legend:\n",
        "        plt.legend(legend) \n",
        "train_loss=[]\n",
        "\n",
        "for ite in range(epochs):\n",
        "    overall_loss =0\n",
        "    train_error = 0    \n",
        "    predictions,Y_hat,sample_list, attention_weights = Attmodel(sequences, samples,count_total )\n",
        "    #get true sample label, for now, use binary\n",
        "    #label_true = [ sample_label_map[s] for s in sample_list ]\n",
        "    #column vectorat\n",
        "    #label_true = np.array( label_true ).reshape( (len(label_true),1) )\n",
        "    #label_true = torch.from_numpy( label_true ).float()\n",
        "    label_true = labels\n",
        "    #Y_hat.shape 10*1\n",
        "    #print(label_true[:5])\n",
        "    #print(Y_hat[:5])\n",
        "    loss = loss_function(predictions, label_true)\n",
        "    overall_loss +=loss.item()\n",
        "    \n",
        "    error, predicted_label = calculate_classification_error(Y_hat, label_true)\n",
        "    train_error += error\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (ite % 1000 == 0):\n",
        "      print('Train Set, Epoch: {}, Loss: {:.4f},Error: {:.4f}, Accuracy: {:.2f}%'.format(ite+1, overall_loss,train_error,accuracy_score(label_true, Y_hat)*100))\n",
        "    train_loss.append(overall_loss/len(sequences))\n",
        "\n",
        "plotCurve(range(1,epochs+1),train_loss,\"epoch\",\"loss\",\n",
        "          ['train'])\n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "DXst0iRdeSwA",
        "outputId": "7819e936-181b-4b34-9858-7de394f0d9ef"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set, Epoch: 1, Loss: 191.1932,Error: 0.5000, Accuracy: 50.00%\n",
            "Train Set, Epoch: 1001, Loss: 191.1932,Error: 0.5000, Accuracy: 50.00%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test model "
      ],
      "metadata": {
        "id": "MuPUz_zDB7kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0.\n",
        "test_error = 0.\n",
        "with torch.no_grad():\n",
        "  predictions,Y_hat,sample_list, attention_weights = Attmodel(sequences, samples,count_total )\n",
        "  label_true = labels\n",
        "  print('Test set, accuracy :{:.2f}%'.format(accuracy_score(labels,Y_hat)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1I4n5JGB67h",
        "outputId": "0e132c6e-faf2-4b8e-c771-357fb0a53ac8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set, accuracy :50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "0gObHi6CQkg9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=list(string.ascii_lowercase)\n",
        "A= A[:len(lung_file)*2]"
      ],
      "metadata": {
        "id": "4csb6gwDQmlH"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples=list(chain.from_iterable((repeat(item, cnt) for item, cnt in zip(A,line_counts))))"
      ],
      "metadata": {
        "id": "4YYesMMUQ0KR"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbtgC-26Qy5e",
        "outputId": "856251ad-da30-41c2-b641-57d2a6394d06"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53570"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-fDVuW7nGtD",
        "outputId": "04d854b6-f460-4439-c914-4724ccbb65ce"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53570"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    }
  ]
}