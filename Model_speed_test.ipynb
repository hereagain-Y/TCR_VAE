{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdFDwJegErWX5eQVkQUqmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hereagain-Y/TCR_VAE/blob/main/Model_speed_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test latent distance calculation on GPU"
      ],
      "metadata": {
        "id": "GuEuq4gXwpY5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g55n4yqyd3IC",
        "outputId": "42886380-dc18-4a35-d22a-4324ec785fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Biopython) (1.21.6)\n",
            "Installing collected packages: Biopython\n",
            "Successfully installed Biopython-1.79\n"
          ]
        }
      ],
      "source": [
        "! pip install Biopython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd \n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pkgutil import extend_path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from six.moves import xrange\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "#\n",
        "from scipy.spatial import distance\n",
        "import random \n",
        "from Bio import pairwise2\n",
        "from Bio.Align import substitution_matrices\n",
        "from scipy import spatial\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "ghL3m2j2hVYV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81eNsV8Ehgmj",
        "outputId": "e8f4f554-c389-4aec-fe05-6c0e35315d62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AAs= ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "index_code = {}\n",
        "code_index = {}\n",
        "l_max = 20\n",
        "for i in range(len(AAs)):\n",
        "    index_code[i] = AAs[i]\n",
        "    code_index[ AAs[i] ] = i\n",
        "\n",
        "def oneHotEncode(seq, l_max=l_max, index_code=index_code, code_index=code_index):\n",
        "    n_amino = 20\n",
        "    matrix = np.zeros((l_max,n_amino)).astype(int)\n",
        "    for i in range(len(seq)):\n",
        "        matrix[ i , code_index[seq[i]] ] = 1\n",
        "    return matrix\n",
        "\n",
        "# pca encoded \n",
        "pca_index = pd.read_csv(\"/content/drive/My Drive/DL/VAE/AA_indexPCA.csv\")\n",
        "d=pca_index.set_index('Unnamed: 0').T.to_dict('list')\n",
        "\n",
        "\n",
        "# pca normalization\n",
        "data = d.items()\n",
        "list_dat = list(d.values())\n",
        "arr = np.array(list_dat)\n",
        "ex = np.array(arr)\n",
        "ex_norm = (ex-ex.min(axis=0))/(ex.max(axis=0)-ex.min(axis=0))\n",
        "\n",
        "AAs=np.array(list(d.keys()))\n",
        "new_pca = {}\n",
        "\n",
        "for i in np.arange(20):\n",
        "    new_pca[AAs[i]]=ex_norm[i]\n",
        "\n",
        "new_pca\n",
        "d= new_pca\n",
        "\n",
        "def AAindexEncoding(Seq):\n",
        "    length_seq=len(Seq)\n",
        "    global l_max\n",
        "    AAE=np.zeros([l_max,20])\n",
        "    if length_seq<l_max:\n",
        "        for amino in range(length_seq):\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA] # add PC value \n",
        "            \n",
        "        for amino in range(length_seq,l_max):\n",
        "            AAE[amino,]=np.zeros(20)\n",
        "    else: \n",
        "        for amino in range(length_seq): # zero padding\n",
        "            AA=Seq[amino]# \n",
        "            AAE[amino,]=d[AA]\n",
        "        \n",
        "    #AAE=np.transpose(AAE.astype(np.float32)) # row as PC. and column as AA sequence \n",
        "    return AAE \n",
        "\n",
        "  \n",
        "def GetFeatures(file):\n",
        "    hot_encode=[]\n",
        "    for seq in file:\n",
        "        hot_encode.append(AAindexEncoding(seq))\n",
        "    hot_encode=np.array(hot_encode)\n",
        "    result=np.array(hot_encode)\n",
        "    return(result)"
      ],
      "metadata": {
        "id": "GAEdkNvmhpaA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = substitution_matrices.load('BLOSUM62')\n",
        "#from Bio.SubsMat import MatrixInfo as matlist\n",
        "#matrix = matlist.blosum62\n",
        "#in 80 max penalty for substitution is -6,\n",
        "open_penalty = -4\n",
        "gap_penalty = -4\n",
        "#\n",
        "def parseMatrix(m):\n",
        "    re = {}\n",
        "    alpha = m.alphabet\n",
        "    for i in range(len(alpha)):\n",
        "        for j in range(i,len(alpha)):\n",
        "            re[(alpha[i],alpha[j])] = m[i,j]\n",
        "    return re\n",
        "align_matrix =  parseMatrix(substitution_matrices.load('BLOSUM62'))"
      ],
      "metadata": {
        "id": "BApGObXehuoQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_test = pd.read_csv('/content/drive/My Drive/DL/VAE/NormalCDR3.txt',delimiter='\\t',header=None,names=['seq'])\n",
        "seq_test['length'] = [len(seq) for seq in seq_test['seq']]\n",
        "\n",
        "seq_test = seq_test[ seq_test['length']<=20 ]\n",
        "seq = list( seq_test['seq'] )\n",
        "seq_x = random.sample(seq,100)\n",
        "input1 = []\n",
        "input2 =[]\n",
        "for pair in itertools.combinations(seq_x, 2):\n",
        "  \n",
        "    input1.append(pair[0])\n",
        "    input2.append(pair[1])\n",
        "\n",
        "# alignment on x y \n",
        "score_align=[]\n",
        "for i in range(len(input1)):\n",
        "    \n",
        "  alignments = pairwise2.align.localds(input1[i], input2[i], align_matrix, open=open_penalty, extend=gap_penalty)\n",
        "  score_align.append(alignments[0].score)\n",
        "\n",
        "AA_matx= GetFeatures(input1)\n",
        "AA_maty= GetFeatures(input2)\n",
        "\n",
        "\n",
        "#seq_train_x = AA_matx # 20*20\n",
        "#seq_train_y = AA_maty\n",
        "\n",
        "#train_data=[]\n",
        "#for i in range(len(AA_matx)):\n",
        "#  train_data.append([AA_matx[i],score_align[i]])\n",
        "trainloader_x = torch.utils.data.DataLoader([ [torch.from_numpy(AA_matx[i]).float(),score_align[i]] for i in range(len(score_align))],  batch_size=1000)\n",
        "#i1, l1 = next(iter(trainloader))\n",
        "#print(l1.shape)\n",
        "trainloader_y = torch.utils.data.DataLoader([ [torch.from_numpy(AA_maty[i]).float(),score_align[i]] for i in range(len(score_align))],  batch_size=1000)"
      ],
      "metadata": {
        "id": "lxMWS59Mhw1A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(trainloader_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdWBfYQQkQRY",
        "outputId": "a8133e93-5d3b-4060-8729-3e50cece712e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=datetime.now()"
      ],
      "metadata": {
        "id": "M_acp4p4i2il"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True\n",
        "channels =1\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
      ],
      "metadata": {
        "id": "FV6qxP4HjDZ2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self,h_dim=64*10*10, z_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1), #16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1), # 12\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1), #10\n",
        "            nn.ReLU()\n",
        "        \n",
        "        )\n",
        "\n",
        "        \n",
        "        \n",
        "        # mean 64*5*5 =\n",
        "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
        "        # var \n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        # for decoder layer \n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            \n",
        "   \n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def reparameterize(self, mu):\n",
        "        #std = logvar.mul(0.5).exp_()\n",
        "        # return torch.normal(mu, std)\n",
        "        #esp = torch.randn(*mu.size())\n",
        "        z = mu\n",
        "        return z\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu= self.fc1(h)\n",
        "        z = self.reparameterize(mu)\n",
        "        return mu, z\n",
        "        \n",
        "    def representation(self, x):\n",
        "        return self.bottleneck(self.encoder(x))[0] # latent layer \n",
        "\n",
        "        \n",
        "    \n",
        "    #def alignmentscore(self,x,y):\n",
        "    #    scores = pairwise2.align.localds(x,y,align_matrix,open=open_penalty,extend=gap_penalty)\n",
        "    #    score_align = scores[0].score\n",
        "    #    return score_align\n",
        "        \n",
        "    def latent(self,x,y):\n",
        "        l1 = self.encoder(x)# 32\n",
        "        l1 = l1.view(-1,64*10*10) # 32\n",
        "        l1, mu1 = self.bottleneck(l1)\n",
        "\n",
        "        l2 = self.encoder(y)# 32\n",
        "        l2 = l2.view(-1,64*10*10) # 32\n",
        "        l2, mu2 = self.bottleneck(l2)\n",
        "        # use cos-simialrity\n",
        "        #latent_dist =np.sqrt( np.sum(np.square(l1 - l2)) )\n",
        "        \n",
        "        \n",
        "        return l1,l2\n",
        "\n",
        "    def forward(self, x,y):\n",
        "      # for dataset 1\n",
        "        h1= self.encoder(x)\n",
        "        h1 = h1.view(-1,64*10*10)\n",
        "        z1, mu1 = self.bottleneck(h1) #\n",
        "        z1 = self.fc3(z1) # 64*10*10\n",
        "        z1 = z1.view(-1,64,10,10)\n",
        "        z1 = self.decoder(z1)\n",
        "      # for dat2   \n",
        "        h2= self.encoder(y)\n",
        "        h2 = h2.view(-1,64*10*10)\n",
        "        z2, mu2 = self.bottleneck(h2)\n",
        "        z2 = self.fc3(z2)\n",
        "        z2 = z2.view(-1,64,10,10)\n",
        "        z2 = self.decoder(z2)\n",
        "        \n",
        "        # aligment \n",
        "        #s = self.alignmentscore(x,y)\n",
        "        # latent distance\n",
        "        l1,l2 = self.latent(x,y)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return z1, mu1,z2,mu2,l1,l2"
      ],
      "metadata": {
        "id": "u3y3cf7ajE5l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torch.load('/content/drive/MyDrive/DL/CNNVAE/Paired_sigmoid_modified_1000_echo_cat_train.apx')"
      ],
      "metadata": {
        "id": "SQhWk3kKjK1b"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move model to gpu\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "-xZnHK8bv5QX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance1=[]\n",
        "distance2=[]\n",
        "delta=[]"
      ],
      "metadata": {
        "id": "2ua6vLaljR0f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, data in enumerate(zip(trainloader_x,trainloader_y)):\n",
        "  x= data[0][0]\n",
        "  y= data[1][0]\n",
        "  score = data[0][1].to(device)\n",
        "  x = x.view(len(x), 1,20,20)\n",
        "  y = y.view(len(x), 1,20,20)\n",
        "  x = x.to(device)\n",
        "  y = y.to(device)\n",
        "  x_hat, mean_x,y_hat,mean_y,l1,l2= model(x,y)\n",
        "  dis = torch.nn.functional.pairwise_distance(l1, l2,2)\n",
        "  delta.append(dis)\n",
        " "
      ],
      "metadata": {
        "id": "W84-3B02jVbH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeMUcxRlG-P",
        "outputId": "bb086121-452b-4b43-e310-9d784ed53506"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_tensor = torch.cat(delta)\n",
        "stacked_tensor.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyBShMNqo6fA",
        "outputId": "ef95d03e-c1d3-46ed-c7f3-7c5c3dbb79c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4950"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distance=stacked_tensor.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "-XuwgErTpUpZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xkR_DPMwOvC",
        "outputId": "c69c0980-6a29-4c58-d867-2cd01adc188b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4950,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pd.DataFrame(columns=['seq1','seq2','alignment_score','latent_dist'])"
      ],
      "metadata": {
        "id": "TqGSsLvjpXmz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XCJoBNg1o6Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_out['seq1'] = input1\n",
        "df_out['seq_2']=input2\n",
        "\n",
        "df_out['alignment_score'] = score_align\n",
        "df_out['latent_dist'] = distance\n",
        "df_out.to_csv('/content/drive/MyDrive/DL/CNNVAE/speed_testing.csv',index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wau-nuR_wJ7o"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}